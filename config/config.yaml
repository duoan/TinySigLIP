# TinySigLIP Training Configuration

# Model configuration
teacher:
  model_name: "google/siglip2-base-patch16-224"

student:
  vision_model_name: "vit_tiny_patch16_224"
  vision_dim: 384
  text_dim: 384
  text_layers: 4
  text_nhead: 8  # Number of attention heads in text transformer
  text_ff_dim_multiplier: 4  # Feedforward dimension = text_dim * text_ff_dim_multiplier
  projection_dim: 384
  vocab_size: 32000  # Smaller vocab for English-only
  tokenizer_name: 'google/siglip-base-patch16-224'  # Use teacher tokenizer if None

# Training configuration
training:
  batch_size: 16
  image_size: 224
  text_seq_len: 64
  max_steps: 1000
  learning_rate: 5.0e-5
  warmup_steps: 100
  use_cosine_scheduler: true

# Loss configuration
loss:
  lambda_siglip: 0.5
  lambda_cmd: 1.0
  lambda_umd: 1.0
  temperature: 3.0

# Dataset configuration
dataset:
  use_real_data: true
  split: "val"  # 'val' or 'test'
  cache_dir: null
  use_augmentation: true
  streaming: true

# Embedding configuration
embedding:
  use_weight_transfer: true  # One-time weight transfer (recommended)
  overlap_ratio: 0.8  # For dummy token mapping

# Output configuration
output:
  save_dir: "outputs"
  checkpoint_name: "checkpoint.pt"

# Logging
logging:
  log_every_n_steps: 100
  eval_every_n_steps: 100  # Compute evaluation metrics every N steps

# WandB configuration
wandb:
  enabled: true
  project: "tinysiglip"
  entity: null  # Set your wandb entity/username here, or leave null
  name: null  # Run name, will auto-generate if null
  tags: []
  notes: ""

# Hydra configuration
defaults:
  - _self_

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d_%H-%M-%S}
  job:
    name: tinysiglip_train
