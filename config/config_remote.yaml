# TinySigLIP Training Configuration for Remote Server
# Optimized for (8x A100 40GB GPUs)
# Inherits from config.yaml and only overrides specific settings

defaults:
  - config  # Inherit from config.yaml
  - _self_

# Training configuration overrides for 8x A100 40GB
# Effective batch size = batch_size × 8 GPUs = 128 × 8 = 1024
training:
  batch_size: 128  # Per GPU batch size (effective: 1024 with 8 GPUs)
  num_epochs: 2  # ~1-2 epochs on COCO train set
  learning_rate: 4.0e-4  # Scaled for large batch size (sqrt scaling: 5e-5 × sqrt(1024/16) ≈ 4e-4)
  warmup_epochs: 0.1  # ~6% of training for stable training start

# Dataset configuration overrides
dataset:
  split: "train"  # Use 'train' for actual training on remote server
  streaming: false  # Disable streaming to allow more num_workers (streaming limits workers by shards)
  num_workers: 16  # More workers for faster data loading (reduce GPU idle time)

# Early stopping configuration overrides for remote training
early_stopping:
  patience: 100  # More patience for remote training (100 steps)
